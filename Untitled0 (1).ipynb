{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_w4ruhJcTNZ"
      },
      "outputs": [],
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 120\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "sAzBc2QDcVgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y39nL1HdccTp",
        "outputId": "b1dae977-05c5-4599-98d3-6986746fd42e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert class vectors to binary class matrices\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "tz9ZfpHxcfBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "# prepare iterator\n",
        "it_train = datagen.flow(x_train, y_train, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "36-SwT6GL-Cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "opt = Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "    #EarlyStopping(monitor='loss', patience=3),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
        "]\n",
        "\n",
        "steps = int(x_train.shape[0] / batch_size)\n",
        "model.fit(it_train, steps_per_epoch=steps, epochs=epochs, validation_data=(x_test, y_test), verbose=1, callbacks=callbacks)\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "l919knBmcjHR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "677ffe19-983f-4a76-a183-8fa13f1d9b39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "781/781 [==============================] - 38s 47ms/step - loss: 1.8310 - accuracy: 0.3774 - val_loss: 1.4304 - val_accuracy: 0.4801 - lr: 0.0100\n",
            "Epoch 2/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 1.1848 - accuracy: 0.5762 - val_loss: 1.2343 - val_accuracy: 0.5950 - lr: 0.0100\n",
            "Epoch 3/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.9381 - accuracy: 0.6718 - val_loss: 0.8579 - val_accuracy: 0.7038 - lr: 0.0100\n",
            "Epoch 4/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.7985 - accuracy: 0.7254 - val_loss: 0.6980 - val_accuracy: 0.7626 - lr: 0.0100\n",
            "Epoch 5/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.7339 - accuracy: 0.7492 - val_loss: 0.7939 - val_accuracy: 0.7393 - lr: 0.0100\n",
            "Epoch 6/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.6734 - accuracy: 0.7706 - val_loss: 0.8704 - val_accuracy: 0.7308 - lr: 0.0100\n",
            "Epoch 7/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.6263 - accuracy: 0.7885 - val_loss: 0.8773 - val_accuracy: 0.7267 - lr: 0.0100\n",
            "Epoch 8/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.5956 - accuracy: 0.7991 - val_loss: 0.6025 - val_accuracy: 0.7963 - lr: 0.0100\n",
            "Epoch 9/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.5562 - accuracy: 0.8128 - val_loss: 0.6655 - val_accuracy: 0.7899 - lr: 0.0100\n",
            "Epoch 10/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.5300 - accuracy: 0.8213 - val_loss: 0.5786 - val_accuracy: 0.8192 - lr: 0.0100\n",
            "Epoch 11/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.5042 - accuracy: 0.8304 - val_loss: 0.6790 - val_accuracy: 0.7936 - lr: 0.0100\n",
            "Epoch 12/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.4776 - accuracy: 0.8381 - val_loss: 0.5571 - val_accuracy: 0.8268 - lr: 0.0100\n",
            "Epoch 13/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.4582 - accuracy: 0.8458 - val_loss: 0.5426 - val_accuracy: 0.8303 - lr: 0.0100\n",
            "Epoch 14/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.4374 - accuracy: 0.8526 - val_loss: 0.4853 - val_accuracy: 0.8514 - lr: 0.0100\n",
            "Epoch 15/120\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.4195 - accuracy: 0.8585 - val_loss: 0.4454 - val_accuracy: 0.8584 - lr: 0.0100\n",
            "Epoch 16/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.4167 - accuracy: 0.8609 - val_loss: 0.4164 - val_accuracy: 0.8639 - lr: 0.0100\n",
            "Epoch 17/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.3923 - accuracy: 0.8687 - val_loss: 0.4192 - val_accuracy: 0.8660 - lr: 0.0100\n",
            "Epoch 18/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.3746 - accuracy: 0.8748 - val_loss: 0.4709 - val_accuracy: 0.8616 - lr: 0.0100\n",
            "Epoch 19/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.3805 - accuracy: 0.8721 - val_loss: 0.5233 - val_accuracy: 0.8485 - lr: 0.0100\n",
            "Epoch 20/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3457 - accuracy: 0.8840 - val_loss: 0.3738 - val_accuracy: 0.8795 - lr: 0.0100\n",
            "Epoch 21/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.3440 - accuracy: 0.8840 - val_loss: 0.4131 - val_accuracy: 0.8751 - lr: 0.0100\n",
            "Epoch 22/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.3364 - accuracy: 0.8865 - val_loss: 0.3945 - val_accuracy: 0.8749 - lr: 0.0100\n",
            "Epoch 23/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3291 - accuracy: 0.8886 - val_loss: 0.4678 - val_accuracy: 0.8598 - lr: 0.0100\n",
            "Epoch 24/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.3148 - accuracy: 0.8958 - val_loss: 0.4439 - val_accuracy: 0.8643 - lr: 0.0100\n",
            "Epoch 25/120\n",
            "781/781 [==============================] - 36s 45ms/step - loss: 0.3071 - accuracy: 0.8979 - val_loss: 0.7164 - val_accuracy: 0.7776 - lr: 0.0100\n",
            "Epoch 26/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.2409 - accuracy: 0.9169 - val_loss: 0.3189 - val_accuracy: 0.8996 - lr: 0.0020\n",
            "Epoch 27/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.2033 - accuracy: 0.9300 - val_loss: 0.3055 - val_accuracy: 0.9065 - lr: 0.0020\n",
            "Epoch 28/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.1873 - accuracy: 0.9357 - val_loss: 0.3087 - val_accuracy: 0.9075 - lr: 0.0020\n",
            "Epoch 29/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.1796 - accuracy: 0.9387 - val_loss: 0.3207 - val_accuracy: 0.9032 - lr: 0.0020\n",
            "Epoch 30/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.1710 - accuracy: 0.9401 - val_loss: 0.3017 - val_accuracy: 0.9077 - lr: 0.0020\n",
            "Epoch 31/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.1626 - accuracy: 0.9442 - val_loss: 0.3411 - val_accuracy: 0.9010 - lr: 0.0020\n",
            "Epoch 32/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.1590 - accuracy: 0.9448 - val_loss: 0.3274 - val_accuracy: 0.9080 - lr: 0.0020\n",
            "Epoch 33/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.1546 - accuracy: 0.9467 - val_loss: 0.3012 - val_accuracy: 0.9124 - lr: 0.0020\n",
            "Epoch 34/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.1460 - accuracy: 0.9497 - val_loss: 0.2975 - val_accuracy: 0.9144 - lr: 0.0020\n",
            "Epoch 35/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.1411 - accuracy: 0.9516 - val_loss: 0.3007 - val_accuracy: 0.9106 - lr: 0.0020\n",
            "Epoch 36/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.1390 - accuracy: 0.9522 - val_loss: 0.3253 - val_accuracy: 0.9082 - lr: 0.0020\n",
            "Epoch 37/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.1331 - accuracy: 0.9529 - val_loss: 0.3094 - val_accuracy: 0.9140 - lr: 0.0020\n",
            "Epoch 38/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.1331 - accuracy: 0.9545 - val_loss: 0.3252 - val_accuracy: 0.9081 - lr: 0.0020\n",
            "Epoch 39/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.1251 - accuracy: 0.9564 - val_loss: 0.3242 - val_accuracy: 0.9097 - lr: 0.0020\n",
            "Epoch 40/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.1184 - accuracy: 0.9590 - val_loss: 0.3100 - val_accuracy: 0.9171 - lr: 0.0010\n",
            "Epoch 41/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.1138 - accuracy: 0.9604 - val_loss: 0.3240 - val_accuracy: 0.9154 - lr: 0.0010\n",
            "Epoch 42/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.1143 - accuracy: 0.9611 - val_loss: 0.3093 - val_accuracy: 0.9182 - lr: 0.0010\n",
            "Epoch 43/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.1110 - accuracy: 0.9614 - val_loss: 0.3186 - val_accuracy: 0.9165 - lr: 0.0010\n",
            "Epoch 44/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.1072 - accuracy: 0.9632 - val_loss: 0.3183 - val_accuracy: 0.9128 - lr: 0.0010\n",
            "Epoch 45/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.1053 - accuracy: 0.9633 - val_loss: 0.3135 - val_accuracy: 0.9166 - lr: 0.0010\n",
            "Epoch 46/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0997 - accuracy: 0.9665 - val_loss: 0.3162 - val_accuracy: 0.9183 - lr: 0.0010\n",
            "Epoch 47/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0969 - accuracy: 0.9652 - val_loss: 0.3201 - val_accuracy: 0.9159 - lr: 0.0010\n",
            "Epoch 48/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0993 - accuracy: 0.9652 - val_loss: 0.3066 - val_accuracy: 0.9190 - lr: 0.0010\n",
            "Epoch 49/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.1007 - accuracy: 0.9648 - val_loss: 0.3182 - val_accuracy: 0.9161 - lr: 0.0010\n",
            "Epoch 50/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0948 - accuracy: 0.9672 - val_loss: 0.3215 - val_accuracy: 0.9174 - lr: 0.0010\n",
            "Epoch 51/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0981 - accuracy: 0.9663 - val_loss: 0.3051 - val_accuracy: 0.9180 - lr: 0.0010\n",
            "Epoch 52/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0890 - accuracy: 0.9681 - val_loss: 0.3164 - val_accuracy: 0.9180 - lr: 0.0010\n",
            "Epoch 53/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.0933 - accuracy: 0.9679 - val_loss: 0.3291 - val_accuracy: 0.9159 - lr: 0.0010\n",
            "Epoch 54/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0917 - accuracy: 0.9682 - val_loss: 0.3211 - val_accuracy: 0.9181 - lr: 0.0010\n",
            "Epoch 55/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0887 - accuracy: 0.9686 - val_loss: 0.3280 - val_accuracy: 0.9168 - lr: 0.0010\n",
            "Epoch 56/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0882 - accuracy: 0.9694 - val_loss: 0.3161 - val_accuracy: 0.9178 - lr: 0.0010\n",
            "Epoch 57/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0870 - accuracy: 0.9707 - val_loss: 0.3251 - val_accuracy: 0.9172 - lr: 0.0010\n",
            "Epoch 58/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0822 - accuracy: 0.9709 - val_loss: 0.3329 - val_accuracy: 0.9176 - lr: 0.0010\n",
            "Epoch 59/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0817 - accuracy: 0.9713 - val_loss: 0.3247 - val_accuracy: 0.9179 - lr: 0.0010\n",
            "Epoch 60/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.0846 - accuracy: 0.9700 - val_loss: 0.3343 - val_accuracy: 0.9178 - lr: 0.0010\n",
            "Epoch 61/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0850 - accuracy: 0.9699 - val_loss: 0.3185 - val_accuracy: 0.9193 - lr: 0.0010\n",
            "Epoch 62/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0797 - accuracy: 0.9721 - val_loss: 0.3188 - val_accuracy: 0.9191 - lr: 0.0010\n",
            "Epoch 63/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0767 - accuracy: 0.9728 - val_loss: 0.3290 - val_accuracy: 0.9171 - lr: 0.0010\n",
            "Epoch 64/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0801 - accuracy: 0.9721 - val_loss: 0.3224 - val_accuracy: 0.9186 - lr: 0.0010\n",
            "Epoch 65/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0816 - accuracy: 0.9707 - val_loss: 0.3418 - val_accuracy: 0.9172 - lr: 0.0010\n",
            "Epoch 66/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0771 - accuracy: 0.9730 - val_loss: 0.3394 - val_accuracy: 0.9196 - lr: 0.0010\n",
            "Epoch 67/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0737 - accuracy: 0.9740 - val_loss: 0.3423 - val_accuracy: 0.9188 - lr: 0.0010\n",
            "Epoch 68/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0761 - accuracy: 0.9728 - val_loss: 0.3322 - val_accuracy: 0.9197 - lr: 0.0010\n",
            "Epoch 69/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.0744 - accuracy: 0.9742 - val_loss: 0.3275 - val_accuracy: 0.9187 - lr: 0.0010\n",
            "Epoch 70/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0733 - accuracy: 0.9741 - val_loss: 0.3344 - val_accuracy: 0.9199 - lr: 0.0010\n",
            "Epoch 71/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0717 - accuracy: 0.9752 - val_loss: 0.3457 - val_accuracy: 0.9179 - lr: 0.0010\n",
            "Epoch 72/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.0726 - accuracy: 0.9750 - val_loss: 0.3337 - val_accuracy: 0.9194 - lr: 0.0010\n",
            "Epoch 73/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0700 - accuracy: 0.9752 - val_loss: 0.3341 - val_accuracy: 0.9197 - lr: 0.0010\n",
            "Epoch 74/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0707 - accuracy: 0.9756 - val_loss: 0.3441 - val_accuracy: 0.9185 - lr: 0.0010\n",
            "Epoch 75/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0691 - accuracy: 0.9760 - val_loss: 0.3377 - val_accuracy: 0.9173 - lr: 0.0010\n",
            "Epoch 76/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0698 - accuracy: 0.9756 - val_loss: 0.3371 - val_accuracy: 0.9194 - lr: 0.0010\n",
            "Epoch 77/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.0685 - accuracy: 0.9763 - val_loss: 0.3400 - val_accuracy: 0.9163 - lr: 0.0010\n",
            "Epoch 78/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0686 - accuracy: 0.9759 - val_loss: 0.3428 - val_accuracy: 0.9166 - lr: 0.0010\n",
            "Epoch 79/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.0676 - accuracy: 0.9764 - val_loss: 0.3319 - val_accuracy: 0.9206 - lr: 0.0010\n",
            "Epoch 80/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0637 - accuracy: 0.9783 - val_loss: 0.3451 - val_accuracy: 0.9183 - lr: 0.0010\n",
            "Epoch 81/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0655 - accuracy: 0.9776 - val_loss: 0.3496 - val_accuracy: 0.9187 - lr: 0.0010\n",
            "Epoch 82/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.0645 - accuracy: 0.9776 - val_loss: 0.3448 - val_accuracy: 0.9209 - lr: 0.0010\n",
            "Epoch 83/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0640 - accuracy: 0.9775 - val_loss: 0.3448 - val_accuracy: 0.9184 - lr: 0.0010\n",
            "Epoch 84/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0640 - accuracy: 0.9775 - val_loss: 0.3518 - val_accuracy: 0.9174 - lr: 0.0010\n",
            "Epoch 85/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0614 - accuracy: 0.9788 - val_loss: 0.3582 - val_accuracy: 0.9166 - lr: 0.0010\n",
            "Epoch 86/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.0629 - accuracy: 0.9777 - val_loss: 0.3536 - val_accuracy: 0.9170 - lr: 0.0010\n",
            "Epoch 87/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0585 - accuracy: 0.9792 - val_loss: 0.3575 - val_accuracy: 0.9163 - lr: 0.0010\n",
            "Epoch 88/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0596 - accuracy: 0.9790 - val_loss: 0.3539 - val_accuracy: 0.9195 - lr: 0.0010\n",
            "Epoch 89/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.0604 - accuracy: 0.9788 - val_loss: 0.3562 - val_accuracy: 0.9185 - lr: 0.0010\n",
            "Epoch 90/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.0618 - accuracy: 0.9791 - val_loss: 0.3563 - val_accuracy: 0.9187 - lr: 0.0010\n",
            "Epoch 91/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.0587 - accuracy: 0.9795 - val_loss: 0.3522 - val_accuracy: 0.9197 - lr: 0.0010\n",
            "Epoch 92/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0563 - accuracy: 0.9801 - val_loss: 0.3550 - val_accuracy: 0.9186 - lr: 0.0010\n",
            "Epoch 93/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.0587 - accuracy: 0.9792 - val_loss: 0.3560 - val_accuracy: 0.9193 - lr: 0.0010\n",
            "Epoch 94/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.0599 - accuracy: 0.9791 - val_loss: 0.3516 - val_accuracy: 0.9203 - lr: 0.0010\n",
            "Epoch 95/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.0572 - accuracy: 0.9792 - val_loss: 0.3544 - val_accuracy: 0.9209 - lr: 0.0010\n",
            "Epoch 96/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0590 - accuracy: 0.9788 - val_loss: 0.3550 - val_accuracy: 0.9187 - lr: 0.0010\n",
            "Epoch 97/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0530 - accuracy: 0.9813 - val_loss: 0.3594 - val_accuracy: 0.9187 - lr: 0.0010\n",
            "Epoch 98/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0554 - accuracy: 0.9798 - val_loss: 0.3681 - val_accuracy: 0.9193 - lr: 0.0010\n",
            "Epoch 99/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0526 - accuracy: 0.9823 - val_loss: 0.3711 - val_accuracy: 0.9195 - lr: 0.0010\n",
            "Epoch 100/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0526 - accuracy: 0.9813 - val_loss: 0.3684 - val_accuracy: 0.9158 - lr: 0.0010\n",
            "Epoch 101/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0537 - accuracy: 0.9808 - val_loss: 0.3561 - val_accuracy: 0.9202 - lr: 0.0010\n",
            "Epoch 102/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.0545 - accuracy: 0.9811 - val_loss: 0.3714 - val_accuracy: 0.9187 - lr: 0.0010\n",
            "Epoch 103/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0565 - accuracy: 0.9801 - val_loss: 0.3569 - val_accuracy: 0.9216 - lr: 0.0010\n",
            "Epoch 104/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0535 - accuracy: 0.9808 - val_loss: 0.3645 - val_accuracy: 0.9205 - lr: 0.0010\n",
            "Epoch 105/120\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.0523 - accuracy: 0.9822 - val_loss: 0.3542 - val_accuracy: 0.9215 - lr: 0.0010\n",
            "Epoch 106/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.0510 - accuracy: 0.9821 - val_loss: 0.3688 - val_accuracy: 0.9187 - lr: 0.0010\n",
            "Epoch 107/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0523 - accuracy: 0.9822 - val_loss: 0.3508 - val_accuracy: 0.9208 - lr: 0.0010\n",
            "Epoch 108/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0498 - accuracy: 0.9831 - val_loss: 0.3550 - val_accuracy: 0.9227 - lr: 0.0010\n",
            "Epoch 109/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.0512 - accuracy: 0.9822 - val_loss: 0.3740 - val_accuracy: 0.9194 - lr: 0.0010\n",
            "Epoch 110/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0510 - accuracy: 0.9825 - val_loss: 0.3749 - val_accuracy: 0.9194 - lr: 0.0010\n",
            "Epoch 111/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.0486 - accuracy: 0.9836 - val_loss: 0.3691 - val_accuracy: 0.9205 - lr: 0.0010\n",
            "Epoch 112/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.0516 - accuracy: 0.9826 - val_loss: 0.3566 - val_accuracy: 0.9216 - lr: 0.0010\n",
            "Epoch 113/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.0472 - accuracy: 0.9841 - val_loss: 0.3742 - val_accuracy: 0.9213 - lr: 0.0010\n",
            "Epoch 114/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.0473 - accuracy: 0.9838 - val_loss: 0.3699 - val_accuracy: 0.9214 - lr: 0.0010\n",
            "Epoch 115/120\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.0485 - accuracy: 0.9833 - val_loss: 0.3820 - val_accuracy: 0.9194 - lr: 0.0010\n",
            "Epoch 116/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0439 - accuracy: 0.9849 - val_loss: 0.3776 - val_accuracy: 0.9208 - lr: 0.0010\n",
            "Epoch 117/120\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.0464 - accuracy: 0.9840 - val_loss: 0.3690 - val_accuracy: 0.9207 - lr: 0.0010\n",
            "Epoch 118/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.0459 - accuracy: 0.9839 - val_loss: 0.3801 - val_accuracy: 0.9201 - lr: 0.0010\n",
            "Epoch 119/120\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.0489 - accuracy: 0.9832 - val_loss: 0.3606 - val_accuracy: 0.9207 - lr: 0.0010\n",
            "Epoch 120/120\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.0462 - accuracy: 0.9834 - val_loss: 0.3790 - val_accuracy: 0.9182 - lr: 0.0010\n",
            "Test loss: 0.37904807925224304\n",
            "Test accuracy: 0.9182000160217285\n"
          ]
        }
      ]
    }
  ]
}